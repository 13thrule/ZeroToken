# ZeroToken environment configuration
# Copy this file to .env before running ZeroToken.
#
#   Windows: copy .env.example .env
#   Mac/Linux: cp .env.example .env
#
# All settings below are optional -- ZeroToken works out of the box without a .env file.
# Claude is used via the browser (claude.ai), NOT via the Anthropic API.
# No API keys are required.

# ---------------------------------------------------------------------------
# Ollama model -- used by all four agents: Planner, Patcher, Reviewer, Refiner
# Default: gemma3:4b
# Recommended: gemma3:12b or qwen2.5-coder:7b for better diff quality
# Any model you have pulled locally works:
#   ollama pull gemma3:4b
#   ollama pull gemma3:12b
#   ollama pull qwen2.5-coder:7b
# ---------------------------------------------------------------------------
OLLAMA_MODEL=gemma3:4b

# ---------------------------------------------------------------------------
# Ollama Refiner model override (optional)
# If set, the Refiner agent uses this model instead of OLLAMA_MODEL.
# Leave blank to use the same model as OLLAMA_MODEL.
# ---------------------------------------------------------------------------
OLLAMA_REFINER_MODEL=

# ---------------------------------------------------------------------------
# Ollama context window in tokens (optional)
# Default: 32768  (32k — safe for all hardware with gemma3:4b/12b)
# Increase to 65536 or 131072 for larger codebases if you have the VRAM.
# You can also change this live in the sidebar Models panel inside ZeroToken.
# Note: Larger values require significantly more GPU/CPU memory.
# ---------------------------------------------------------------------------
# OLLAMA_NUM_CTX=32768

# ---------------------------------------------------------------------------
# Ollama host (optional)
# Default: http://localhost:11434
# Change this if Ollama is running on a different machine or port.
# ---------------------------------------------------------------------------
# OLLAMA_HOST=http://localhost:11434
